{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Deep-Learning-For-Tabular-Data\" data-toc-modified-id=\"Deep-Learning-For-Tabular-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Deep Learning For Tabular Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data Preprocessing</a></span></li><li><span><a href=\"#PyTorch-Dataset\" data-toc-modified-id=\"PyTorch-Dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>PyTorch Dataset</a></span></li><li><span><a href=\"#PyTorch-Lightning-Module\" data-toc-modified-id=\"PyTorch-Lightning-Module-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>PyTorch Lightning Module</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Evaluation</a></span></li><li><span><a href=\"#ONNX-Runtime\" data-toc-modified-id=\"ONNX-Runtime-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>ONNX Runtime</a></span></li><li><span><a href=\"#Ending-Notes\" data-toc-modified-id=\"Ending-Notes-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Ending Notes</a></span></li></ul></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:26.180747Z",
     "start_time": "2020-10-27T03:04:26.005266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    html {\n",
       "        font-size: 18px !important;\n",
       "    }\n",
       "\n",
       "    body {\n",
       "        background-color: #FFF !important;\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    body .notebook-app {\n",
       "        background-color: #FFF !important;\n",
       "    }\n",
       "\n",
       "    #header {\n",
       "        box-shadow: none !important;\n",
       "    }\n",
       "\n",
       "    #notebook {\n",
       "        padding-top: 0px;\n",
       "    }\n",
       "\n",
       "    #notebook-container {\n",
       "        box-shadow: none;\n",
       "        -webkit-box-shadow: none;\n",
       "        padding: 10px;\n",
       "    }\n",
       "\n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border: 1px dashed #CCCCCC;\n",
       "    }\n",
       "\n",
       "    .edit_mode div.cell.selected {\n",
       "        border: 1px dashed #828282;\n",
       "    }\n",
       "\n",
       "    div.output_wrapper {\n",
       "        margin-top: 8px;\n",
       "    }\n",
       "\n",
       "    a {\n",
       "        color: #383838;\n",
       "    }\n",
       "\n",
       "    code,\n",
       "    kbd,\n",
       "    pre,\n",
       "    samp {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem !important;\n",
       "    }\n",
       "\n",
       "    h1 {\n",
       "        font-size: 2rem !important;\n",
       "        font-weight: 500 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: uppercase !important;\n",
       "    }\n",
       "\n",
       "    h2 {\n",
       "        font-size: 1.8rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: none !important;\n",
       "    }\n",
       "\n",
       "    h3 {\n",
       "        font-size: 1.5rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        font-style: italic !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    h4,\n",
       "    h5,\n",
       "    h6 {\n",
       "        font-size: 1rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    .prompt {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem;\n",
       "        text-align: right;\n",
       "        line-height: 1.21429rem;\n",
       "    }\n",
       "\n",
       "    /* INTRO PAGE */\n",
       "\n",
       "    .toolbar_info,\n",
       "    .list-container {\n",
       "        ;\n",
       "    }\n",
       "    /* NOTEBOOK */\n",
       "\n",
       "    div#header-container {\n",
       "        display: none !important;\n",
       "    }\n",
       "\n",
       "    div#notebook {\n",
       "        border-top: none;\n",
       "        font-size: 1rem;\n",
       "    }\n",
       "\n",
       "    div.input_prompt {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .code_cell div.input_prompt:after,\n",
       "    div.output_prompt:after {\n",
       "        content: '\\25b6';\n",
       "    }\n",
       "\n",
       "    div.output_prompt {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    div.input_area {\n",
       "        border-radius: 0px;\n",
       "        border: 1px solid #d8d8d8;\n",
       "    }\n",
       "\n",
       "    div.output_area pre {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    div.output_subarea {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .rendered_html pre,\n",
       "    .rendered_html table,\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        border: 1px #828282 solid;\n",
       "        font-size: 0.75rem;\n",
       "        font-family: 'Menlo', monospace;\n",
       "    }\n",
       "\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        padding: 5px 10px;\n",
       "    }\n",
       "\n",
       "    .rendered_html th {\n",
       "        font-weight: normal;\n",
       "        background: #f8f8f8;\n",
       "    }\n",
       "\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "\n",
       "    div.output_html {\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    table.dataframe tr {\n",
       "        border: 1px #CCCCCC;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border-radius: 0px;\n",
       "    }\n",
       "\n",
       "    div.cell.edit_mode {\n",
       "        border-radius: 0px;\n",
       "        border: thin solid #CF5804;\n",
       "    }\n",
       "\n",
       "    span.ansiblue {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    span.ansigray {\n",
       "        color: #d8d8d8;\n",
       "    }\n",
       "\n",
       "    span.ansigreen {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    span.ansipurple {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    span.ansired {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    span.ansiyellow {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    div.output_stderr {\n",
       "        background-color: #D43132;\n",
       "    }\n",
       "\n",
       "    div.output_stderr pre {\n",
       "        color: #e8e8e8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython.CodeMirror {\n",
       "        background: #F8F8F8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython div.CodeMirror-selected {\n",
       "        background: #e8e8e8 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-gutters {\n",
       "        background: #F8F8F8;\n",
       "        border-right: 0px;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-linenumber {\n",
       "        color: #b8b8b8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-cursor {\n",
       "        border-left: 1px solid #585858 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-atom {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-number {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-property,\n",
       "    .cm-s-ipython span.cm-attribute {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-keyword {\n",
       "        font-weight: normal;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-string {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-operator {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-builtin {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable-2 {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-def {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-error {\n",
       "        background: #FFBDBD;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-tag {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-link {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-matchingbracket {\n",
       "        text-decoration: underline;\n",
       "         !important;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir(os.path.join('..', '..', 'notebook_format'))\n",
    "\n",
    "from formats import load_style\n",
    "load_style(css_style='custom2.css', plot_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.482099Z",
     "start_time": "2020-10-27T03:04:26.183212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2020-10-26 20:04:27 \n",
      "\n",
      "CPython 3.6.4\n",
      "IPython 7.15.0\n",
      "\n",
      "numpy 1.18.5\n",
      "pandas 1.0.5\n",
      "sklearn 0.23.1\n",
      "matplotlib 3.1.0\n",
      "torch 1.6.0\n",
      "onnxruntime 1.5.1\n",
      "pytorch_lightning 1.0.1\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# change default style figure and font size\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# prevent scientific notations\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,sklearn,matplotlib,torch,onnxruntime,pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning For Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The success of deep learning is often times mentioned in domains such as computer vision and natural language processing, another use-case that is also powerful but receives far less attention is to use deep learning on tabular data. By tabular data, we are referring to data that we usually put in a dataframe or a relational database, which is one of the most commonly encountered type of data in the industry.\n",
    "\n",
    "One key technique to make the most out of deep learning for tabular data is to use embeddings for our categorical variables. This approach allows for relationship between categories to be captured, e.g. Given a categorical feature with high cardinality (number of distinct categories is large), it often works best to embed the categories into a lower dimensional numeric space, the embeddings might be able to capture zip codes that are geographically near each other without us needing to explicitly tell it so. By converting our raw categories into embeddings, our goal/hope is that these embeddings can capture more rich/complex relationships that will ultimately improve the performance of our models.\n",
    "\n",
    "Another interesting thing about embeddings is that once we train them, we can leverage them in other scenarios. e.g. use these learned embeddings as features for our tree-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the credit card default dataset from UCI, we can download this dataset from [Kaggle](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset) as well.\n",
    "\n",
    "There are many ways to implement the data preprocessing step, the high-level idea is to implement the following workflow:\n",
    "\n",
    "- perform train/validation/test split.\n",
    "- encode categorical columns as distinct numerical ids.\n",
    "- standardize numerical columns.\n",
    "- save the preprocesed data.\n",
    "\n",
    "Here, we chose to preprocess the data once and save the output, so we won't have to go through these preprocessing steps every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.615893Z",
     "start_time": "2020-10-27T03:04:28.484929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>689.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.000</td>\n",
       "      <td>3455.000</td>\n",
       "      <td>3261.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.000</td>\n",
       "      <td>14948.000</td>\n",
       "      <td>15549.000</td>\n",
       "      <td>1518.000</td>\n",
       "      <td>1500.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>5000.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.000</td>\n",
       "      <td>28959.000</td>\n",
       "      <td>29547.000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>2019.000</td>\n",
       "      <td>1200.000</td>\n",
       "      <td>1100.000</td>\n",
       "      <td>1069.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.000</td>\n",
       "      <td>19146.000</td>\n",
       "      <td>19131.000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>36681.000</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>9000.000</td>\n",
       "      <td>689.000</td>\n",
       "      <td>679.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1  20000.000    2          2         1   24      2      2     -1     -1   \n",
       "1   2 120000.000    2          2         2   26     -1      2      0      0   \n",
       "2   3  90000.000    2          2         2   34      0      0      0      0   \n",
       "3   4  50000.000    2          2         1   37      0      0      0      0   \n",
       "4   5  50000.000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...      0.000      0.000      0.000     0.000   689.000     0.000   \n",
       "1  ...   3272.000   3455.000   3261.000     0.000  1000.000  1000.000   \n",
       "2  ...  14331.000  14948.000  15549.000  1518.000  1500.000  1000.000   \n",
       "3  ...  28314.000  28959.000  29547.000  2000.000  2019.000  1200.000   \n",
       "4  ...  20940.000  19146.000  19131.000  2000.000 36681.000 10000.000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0     0.000     0.000     0.000                           1  \n",
       "1  1000.000     0.000  2000.000                           1  \n",
       "2  1000.000  1000.000  5000.000                           0  \n",
       "3  1100.000  1069.000  1000.000                           0  \n",
       "4  9000.000   689.000   679.000                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = 'UCI_Credit_Card.csv'\n",
    "df = pd.read_csv(input_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.657558Z",
     "start_time": "2020-10-27T03:04:28.618660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of categorical columns:  3\n",
      "number of numerical columns:  20\n"
     ]
    }
   ],
   "source": [
    "id_cols = ['ID']\n",
    "cat_cols = ['EDUCATION', 'SEX', 'MARRIAGE']\n",
    "num_cols = [\n",
    "    'LIMIT_BAL', 'AGE',\n",
    "    'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "    'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "    'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
    "]\n",
    "label_col = 'default.payment.next.month'\n",
    "\n",
    "print('number of categorical columns: ', len(cat_cols))\n",
    "print('number of numerical columns: ', len(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.802434Z",
     "start_time": "2020-10-27T03:04:28.659992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (18900, 25)\n",
      "validation shape:  (8100, 25)\n",
      "test shape:  (3000, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9256</th>\n",
       "      <td>9257</td>\n",
       "      <td>20000.000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>480.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23220</th>\n",
       "      <td>23221</td>\n",
       "      <td>150000.000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1143.000</td>\n",
       "      <td>163.000</td>\n",
       "      <td>2036.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2264.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>163.000</td>\n",
       "      <td>2036.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>11075</td>\n",
       "      <td>260000.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2500.000</td>\n",
       "      <td>2500.000</td>\n",
       "      <td>2500.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1584</td>\n",
       "      <td>50000.000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17793.000</td>\n",
       "      <td>18224.000</td>\n",
       "      <td>18612.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2200.000</td>\n",
       "      <td>700.000</td>\n",
       "      <td>700.000</td>\n",
       "      <td>674.000</td>\n",
       "      <td>608.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <td>8624</td>\n",
       "      <td>390000.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3971.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "9256    9257  20000.000    2          3         1   23      1      2      2   \n",
       "23220  23221 150000.000    2          3         2   35     -1      2     -1   \n",
       "11074  11075 260000.000    2          2         1   43      2      2      2   \n",
       "1583    1584  50000.000    2          1         2   70      2      2      0   \n",
       "8623    8624 390000.000    2          2         1   45      1     -2     -2   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "9256      -2  ...      0.000      0.000      0.000   480.000     0.000   \n",
       "23220      2  ...   1143.000    163.000   2036.000     0.000  2264.000   \n",
       "11074      2  ...   2500.000   2500.000   2500.000     0.000     0.000   \n",
       "1583       0  ...  17793.000  18224.000  18612.000     0.000  2200.000   \n",
       "8623      -2  ...      0.000      0.000      0.000     0.000     0.000   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "9256      0.000     0.000     0.000     0.000                           1  \n",
       "23220     0.000   163.000  2036.000     0.000                           0  \n",
       "11074     0.000     0.000     0.000     0.000                           1  \n",
       "1583    700.000   700.000   674.000   608.000                           0  \n",
       "8623      0.000     0.000     0.000  3971.000                           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.1\n",
    "val_size = 0.3\n",
    "random_state = 1234\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    stratify=df[label_col])\n",
    "\n",
    "df_train, df_val = train_test_split(\n",
    "    df_train,\n",
    "    test_size=val_size,\n",
    "    random_state=random_state,\n",
    "    stratify=df_train[label_col])\n",
    "\n",
    "print('train shape: ', df_train.shape)\n",
    "print('validation shape: ', df_val.shape)\n",
    "print('test shape: ', df_test.shape)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.847396Z",
     "start_time": "2020-10-27T03:04:28.805515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EDUCATION': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6},\n",
       " 'SEX': {1: 0, 2: 1},\n",
       " 'MARRIAGE': {0: 0, 1: 1, 2: 2, 3: 3}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the category code mapping, so we can encode any new incoming data\n",
    "# other than our training set\n",
    "cat_code_dict = {}\n",
    "for col in cat_cols:\n",
    "    category_col = df_train[col].astype('category')\n",
    "    cat_code_dict[col] = {value: idx for idx, value in enumerate(category_col.cat.categories)} \n",
    "\n",
    "cat_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.900305Z",
     "start_time": "2020-10-27T03:04:28.849839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.940970Z",
     "start_time": "2020-10-27T03:04:28.901959Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(df, scaler, cat_code_dict, num_cols, cat_cols, label_col):\n",
    "    df = df.copy()\n",
    "\n",
    "    # numeric fields\n",
    "    df[num_cols] = scaler.transform(df[num_cols])\n",
    "    df[num_cols] = df[num_cols].astype(np.float32)\n",
    "\n",
    "    # categorical fields\n",
    "    for col in cat_cols:\n",
    "        code_dict = cat_code_dict[col]\n",
    "        code_fillna_value = len(code_dict)\n",
    "        df[col] = df[col].map(code_dict).fillna(code_fillna_value).astype(np.int64)\n",
    "\n",
    "    # label\n",
    "    df[label_col] = df[label_col].astype(np.float32)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:29.849670Z",
     "start_time": "2020-10-27T03:04:28.943352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                              int64\n",
       "LIMIT_BAL                     float32\n",
       "SEX                             int64\n",
       "EDUCATION                       int64\n",
       "MARRIAGE                        int64\n",
       "AGE                           float32\n",
       "PAY_0                         float32\n",
       "PAY_2                         float32\n",
       "PAY_3                         float32\n",
       "PAY_4                         float32\n",
       "PAY_5                         float32\n",
       "PAY_6                         float32\n",
       "BILL_AMT1                     float32\n",
       "BILL_AMT2                     float32\n",
       "BILL_AMT3                     float32\n",
       "BILL_AMT4                     float32\n",
       "BILL_AMT5                     float32\n",
       "BILL_AMT6                     float32\n",
       "PAY_AMT1                      float32\n",
       "PAY_AMT2                      float32\n",
       "PAY_AMT3                      float32\n",
       "PAY_AMT4                      float32\n",
       "PAY_AMT5                      float32\n",
       "PAY_AMT6                      float32\n",
       "default.payment.next.month    float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups = {\n",
    "    'train': df_train,\n",
    "    'val': df_val,\n",
    "    'test': df_test\n",
    "}\n",
    "\n",
    "data_dir = 'onnx_data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "for name, df_group in df_groups.items():\n",
    "    filename = os.path.join(data_dir, f'{name}.csv')\n",
    "    df_preprocessed = preprocess(df_group, scaler, cat_code_dict, num_cols, cat_cols, label_col)\n",
    "    df_preprocessed.to_csv(filename, index=False)\n",
    "\n",
    "df_preprocessed.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few code chunk involves understanding how to work with [Pytorch's Dataset and DataLoader](https://pytorch.org/docs/stable/data.html). We define a custom Dataset that allows us the load our preprocessed .csv file, and extract the numerical, categorical, and label columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:29.888854Z",
     "start_time": "2020-10-27T03:04:29.851805Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:29.931182Z",
     "start_time": "2020-10-27T03:04:29.891258Z"
    }
   },
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, num_cols, cat_cols, label_col):\n",
    "        self.path = path\n",
    "        self.num_cols = num_cols\n",
    "        self.cat_cols = cat_cols\n",
    "        self.label_col = label_col\n",
    "        self.df = read_data(path, num_cols, cat_cols, label_col)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        num_array = self.df[self.num_cols].iloc[idx].values\n",
    "        cat_array = self.df[self.cat_cols].iloc[idx].values\n",
    "        label_array = self.df[self.label_col].iloc[idx]\n",
    "        return num_array, cat_array, label_array\n",
    "\n",
    "\n",
    "def read_data(path, num_cols, cat_cols, label_col):\n",
    "    float_cols = num_cols + [label_col]\n",
    "    dtype = {col: np.float32 for col in float_cols}\n",
    "    dtype.update({col: np.int64 for col in cat_cols})\n",
    "    return pd.read_csv(path, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:30.057735Z",
     "start_time": "2020-10-27T03:04:29.936792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical value tensor:\n",
      " tensor([[-1.1365, -1.3578,  0.8985,  1.7693,  1.8037, -1.5156, -1.5167, -1.4744,\n",
      "         -0.4939, -0.4858, -0.6720, -0.6725, -0.6630, -0.6509, -0.3129, -0.2444,\n",
      "         -0.3072, -0.2983, -0.3092, -0.2845],\n",
      "        [-0.1374, -0.0537, -0.8610,  1.7693, -0.6883,  1.9076, -0.6384, -0.6082,\n",
      "         -0.6658, -0.6794, -0.6392, -0.6544, -0.6602, -0.6161, -0.3424, -0.1522,\n",
      "         -0.3072, -0.2882, -0.1755, -0.2845]])\n",
      "categorical value tensor:\n",
      " tensor([[3, 1, 1],\n",
      "        [3, 1, 2]])\n",
      "label tensor:\n",
      " tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "path_train = os.path.join(data_dir, 'train.csv')\n",
    "dataset = TabularDataset(path_train, num_cols, cat_cols, label_col)\n",
    "data_loader = DataLoader(dataset, batch_size)\n",
    "\n",
    "# our data loader now returns batches of numerical/categorical/label tensor\n",
    "num_tensor, cat_tensor, label_tensor = next(iter(data_loader))\n",
    "\n",
    "print('numerical value tensor:\\n', num_tensor)\n",
    "print('categorical value tensor:\\n', cat_tensor)\n",
    "print('label tensor:\\n', label_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that one serious downside for this particular dataset implementation is it reads the entire data into memory, for large datasets, this might not be feasible. We'll leave out this enhancements for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Lightning Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be leveraging [PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/latest/) for organizing our neural network model. I personally find it helpful when it comes to standardizing the structure, and avoid manually writing the training loop compared to vanilla PyTorch. This part is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:30.109820Z",
     "start_time": "2020-10-27T03:04:30.060356Z"
    }
   },
   "outputs": [],
   "source": [
    "class TabularDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_dir, num_cols, cat_cols, label_col, num_workers=2,\n",
    "                 batch_size_train=128, batch_size_val=64, batch_size_test=512):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.num_cols = num_cols\n",
    "        self.cat_cols = cat_cols\n",
    "        self.label_col = label_col\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size_train = batch_size_train\n",
    "        self.batch_size_val = batch_size_val\n",
    "        self.batch_size_test = batch_size_test\n",
    "\n",
    "    def setup(self, stage):\n",
    "        num_cols = self.num_cols\n",
    "        cat_cols = self.cat_cols\n",
    "        label_col = self.label_col\n",
    "        \n",
    "        path_train = os.path.join(self.data_dir, 'train.csv')\n",
    "        self.dataset_train = TabularDataset(path_train, num_cols, cat_cols, label_col)\n",
    "\n",
    "        path_val = os.path.join(self.data_dir, 'val.csv')\n",
    "        self.dataset_val = TabularDataset(path_val, num_cols, cat_cols, label_col)\n",
    "\n",
    "        path_test = os.path.join(self.data_dir, 'test.csv')\n",
    "        self.dataset_test = TabularDataset(path_test, num_cols, cat_cols, label_col)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset_train,\n",
    "            num_workers=self.num_workers,\n",
    "            batch_size=self.batch_size_train,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset_val,\n",
    "            num_workers=self.num_workers,\n",
    "            batch_size=self.batch_size_val,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset_test,\n",
    "            num_workers=self.num_workers,\n",
    "            batch_size=self.batch_size_test,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the highlights of using deep learning with tabular data is to create an embedding layer for each of our categorical features, and concatenate them together with the rest of the other numerical features.\n",
    "\n",
    "```\n",
    "embedding(categorical feature 1) ---\n",
    "                                   |\n",
    "embedding(categorical feature 2) ---------> rest of the layers\n",
    "                                   |\n",
    "numerical features -----------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:30.159556Z",
     "start_time": "2020-10-27T03:04:30.112294Z"
    }
   },
   "outputs": [],
   "source": [
    "class TabularNet(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, num_cols, cat_cols, embedding_size_dict, n_classes,\n",
    "                 embedding_dim_dict=None, learning_rate=0.01):\n",
    "        super().__init__()\n",
    "        \n",
    "        # pytorch lightning black magic, all the arguments can now be\n",
    "        # accessed through self.hparams.[argument]\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.embeddings, total_embedding_dim = self._create_embedding_layers(\n",
    "            cat_cols, embedding_size_dict, embedding_dim_dict)\n",
    "        \n",
    "        # concatenate the numerical variables and the embedding layers\n",
    "        # then proceed with the rest of the sequential flow\n",
    "        in_features = len(num_cols) + total_embedding_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_embedding_layers(cat_cols, embedding_size_dict, embedding_dim_dict):\n",
    "        \"\"\"construct the embedding layer, 1 per each categorical variable\"\"\"\n",
    "        total_embedding_dim = 0\n",
    "        embeddings = {}\n",
    "        for col in cat_cols:\n",
    "            embedding_size = embedding_size_dict[col]\n",
    "            embedding_dim = embedding_dim_dict[col]\n",
    "            total_embedding_dim += embedding_dim\n",
    "            embeddings[col] = nn.Embedding(embedding_size, embedding_dim)\n",
    "\n",
    "        return nn.ModuleDict(embeddings), total_embedding_dim\n",
    "\n",
    "    def forward(self, num_tensor, cat_tensor):\n",
    "\n",
    "        # run through all the categorical variables through its\n",
    "        # own embedding layer and concatenate them together\n",
    "        cat_outputs = []\n",
    "        for i, col in enumerate(self.hparams.cat_cols):\n",
    "            embedding = self.embeddings[col]\n",
    "            cat_output = embedding(cat_tensor[:, i])\n",
    "            cat_outputs.append(cat_output)\n",
    "        \n",
    "        cat_outputs = torch.cat(cat_outputs, dim=1)\n",
    "        \n",
    "        # concatenate the categorical embedding and numerical layer\n",
    "        all_outputs = torch.cat((num_tensor, cat_outputs), dim=1)\n",
    "        \n",
    "        # for binary classification or regression we don't need the additional dimension\n",
    "        final_outputs = self.layers(all_outputs).squeeze(dim=1)\n",
    "        return final_outputs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def compute_loss(self, batch, batch_idx):\n",
    "        num_tensor, cat_tensor, label_tensor = batch\n",
    "        output_tensor = self(num_tensor, cat_tensor)\n",
    "        loss = F.binary_cross_entropy_with_logits(output_tensor, label_tensor)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters including the number of layers, units per layer and the embedding size below are all chosen in a somewhat arbitrary manner, feel free to perform some hyperparameter tuning or tweak the layer definition for better performance.\n",
    "\n",
    "For example, when we don't specify the number of embeddings for our categorical variable, [fastai](https://docs.fast.ai/tabular.model#emb_sz_rule) defines a default number based on a rule of thumb corresponding to the number of distinct values for that categorical feature.\n",
    "\n",
    "\n",
    "> Through trial and error, this general rule takes the lower of two values:\n",
    "> - A dimension space of 600\n",
    "> - A dimension space equal to 1.6 times the cardinality of the variable to 0.56.\n",
    "\n",
    "```python\n",
    "def emb_sz_rule(n_cat):\n",
    "    \"Rule of thumb to pick embedding size corresponding to `n_cat`\"\n",
    "    return min(600, round(1.6 * n_cat ** 0.56))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:30.207028Z",
     "start_time": "2020-10-27T03:04:30.162267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EDUCATION': 3, 'SEX': 1, 'MARRIAGE': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 1\n",
    "\n",
    "embedding_size_dict = {col: len(code) for col, code in cat_code_dict.items()}\n",
    "embedding_dim_dict = {col: embedding_size // 2 for col, embedding_size in embedding_size_dict.items()}\n",
    "embedding_dim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:30.249211Z",
     "start_time": "2020-10-27T03:04:30.208655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularNet(\n",
       "  (embeddings): ModuleDict(\n",
       "    (EDUCATION): Embedding(7, 3)\n",
       "    (MARRIAGE): Embedding(4, 2)\n",
       "    (SEX): Embedding(2, 1)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=26, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_data_module = TabularDataModule(data_dir, num_cols, cat_cols, label_col)\n",
    "\n",
    "# we can print out the network architecture for inspection\n",
    "tabular_model = TabularNet(num_cols, cat_cols, embedding_size_dict, n_classes, embedding_dim_dict)\n",
    "tabular_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon defining the data module, and model module, we can pass it to pytorch lightning's `Trainer` which abstracts the manual training loop process for end users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:50.755513Z",
     "start_time": "2020-10-27T03:04:30.251491Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | embeddings | ModuleDict | 31    \n",
      "1 | layers     | Sequential | 36 K  \n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I1026 20:04:35.695845 4405480896 lightning.py:1288] \n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | embeddings | ModuleDict | 31    \n",
      "1 | layers     | Sequential | 36 K  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227bfd219eb14e16ba68094793c8b787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss')]\n",
    "trainer = pl.Trainer(max_epochs=8, callbacks=callbacks)\n",
    "trainer.fit(tabular_model, tabular_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show how we can use the trained model for inference and evaluation on the test set. For the evaluation, we'll use standard binary classification evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:50.837267Z",
     "start_time": "2020-10-27T03:09:50.757808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02512708, -0.46855184], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model.eval()\n",
    "with torch.no_grad():\n",
    "    model_pred = tabular_model(num_tensor, cat_tensor).cpu().numpy()\n",
    "\n",
    "model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:50.910780Z",
     "start_time": "2020-10-27T03:09:50.839308Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(tabular_model, tabular_data_module):\n",
    "    data_loader = tabular_data_module.test_dataloader()\n",
    "    batch_size = data_loader.batch_size\n",
    "    n_rows = len(tabular_data_module.dataset_test)\n",
    "    \n",
    "    y_true = np.zeros(n_rows, dtype=np.float32)\n",
    "    y_pred = np.zeros(n_rows, dtype=np.float32)\n",
    "    with torch.no_grad():\n",
    "        idx = 0\n",
    "        for num_batch, cat_batch, label_batch in data_loader:\n",
    "            y_output = tabular_model(num_batch, cat_batch)\n",
    "\n",
    "            # we convert the output value to binary classification probability\n",
    "            # with a sigmoid operation, note that this step is specific to the\n",
    "            # problem at hand, and might not apply to say a regression problem\n",
    "            y_prob = torch.sigmoid(y_output).cpu().numpy()\n",
    "\n",
    "            start_idx = idx\n",
    "            idx += batch_size\n",
    "            end_idx = idx\n",
    "            y_pred[start_idx:end_idx] = y_prob\n",
    "            y_true[start_idx:end_idx] = label_batch.cpu().numpy()\n",
    "\n",
    "            if end_idx == n_rows:\n",
    "                break\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:53.690111Z",
     "start_time": "2020-10-27T03:09:50.912891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 1.], dtype=float32),\n",
       " array([0.22540408, 0.18922299, 0.07959805, ..., 0.11537173, 0.1427396 ,\n",
       "        0.51938766], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred = predict(tabular_model, tabular_data_module)\n",
    "y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:53.777836Z",
     "start_time": "2020-10-27T03:09:53.692402Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def compute_score(y_true, y_pred, round_digits=3):\n",
    "    log_loss = round(metrics.log_loss(y_true, y_pred), round_digits)\n",
    "    auc = round(metrics.roc_auc_score(y_true, y_pred), round_digits)\n",
    "\n",
    "    precision, recall, threshold = metrics.precision_recall_curve(y_true, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    mask = ~np.isnan(f1)\n",
    "    f1 = f1[mask]\n",
    "    precision = precision[mask]\n",
    "    recall = recall[mask]\n",
    "\n",
    "    best_index = np.argmax(f1)\n",
    "    threshold = round(threshold[best_index], round_digits)\n",
    "    precision = round(precision[best_index], round_digits)\n",
    "    recall = round(recall[best_index], round_digits)\n",
    "    f1 = round(f1[best_index], round_digits)\n",
    "\n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'threshold': threshold,\n",
    "        'log_loss': log_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:53.846320Z",
     "start_time": "2020-10-27T03:09:53.779838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.768,\n",
       " 'precision': 0.534,\n",
       " 'recall': 0.529,\n",
       " 'f1': 0.531,\n",
       " 'threshold': 0.319,\n",
       " 'log_loss': 0.439}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:56.688300Z",
     "start_time": "2020-10-27T03:09:53.848509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.766,\n",
       " 'precision': 0.508,\n",
       " 'recall': 0.557,\n",
       " 'f1': 0.532,\n",
       " 'threshold': 0.262,\n",
       " 'log_loss': 0.442}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model_loaded = TabularNet.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "tabular_model_loaded.eval()\n",
    "with torch.no_grad():\n",
    "    model_pred_loaded = tabular_model_loaded(num_tensor, cat_tensor).cpu().numpy()\n",
    "\n",
    "y_true, y_pred = predict(tabular_model_loaded, tabular_data_module)\n",
    "compute_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform model inferencing in production, we can export our PyTorch model into ONNX format, and run it using [ONNX Runtime](https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html).\n",
    "\n",
    "We'll first run a sample inference using the original PyTorch model and compare it with the output from ONNX Runtime to verfiy the result matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:56.774236Z",
     "start_time": "2020-10-27T03:09:56.690747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02512708, -0.46855184], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model.eval()\n",
    "with torch.no_grad():\n",
    "    torch_pred = tabular_model(num_tensor, cat_tensor).cpu().numpy()\n",
    "\n",
    "torch_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While exporting our model into ONNX format there are a couple of key parameters that we should specify.\n",
    "\n",
    "- Names of the input/output. Instead of leaving it blank, and letting the underlying engine auto-generate the values, this makes our ONNX model easier to work with during inferencing stage.\n",
    "- dynamic_axes. While exporting the model, we need to pass a sample input to inform the underlying engine about the size/shape. While doing so, it's important that we also specify the first dimension (batch size) of our model to be dynamic. This ensures during inferencing stage, the input batch size will not be fixed to the sample input's batch size we provided, but can take on any dynamic value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:56.908870Z",
     "start_time": "2020-10-27T03:09:56.776344Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = 'model.onnx'\n",
    "args = num_tensor, cat_tensor\n",
    "input_names = ['num_tensor', 'cat_tensor']\n",
    "output_names = ['score']\n",
    "dynamic_axes = {\n",
    "    'num_tensor': {0 : 'batch_size'},\n",
    "    'cat_tensor' : {0 : 'batch_size'}\n",
    "}\n",
    "\n",
    "torch.onnx.export(\n",
    "    tabular_model,\n",
    "    args,\n",
    "    filepath,\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    dynamic_axes=dynamic_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:57.019169Z",
     "start_time": "2020-10-27T03:09:56.911238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.02512729, -0.46855184], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "# create the onnx runtime with the exported .onnx model file \n",
    "ort_session = onnxruntime.InferenceSession(filepath)\n",
    "\n",
    "# during inference time, we can be very specific about inputs and outputs\n",
    "ort_inputs = {\n",
    "    'num_tensor': num_tensor.detach().numpy(),\n",
    "    'cat_tensor': cat_tensor.detach().numpy()\n",
    "}\n",
    "# call .run on the onnx runtime session with the desired input and output\n",
    "# the output is a list, but we only need the first output for this example\n",
    "ort_pred = ort_session.run(['score'], ort_inputs)[0]\n",
    "\n",
    "np.allclose(torch_pred, ort_pred)\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")\n",
    "ort_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we converted our model to an onnx format, we can also leverage APIs in different languages to run the inference step. e.g. [onnxruntime's Java API](https://github.com/microsoft/onnxruntime/blob/master/docs/Java_API.md) for performing scoring on a JVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ending Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many enhancements that can be introduced such as:\n",
    "\n",
    "- making the preprocessing step more robust\n",
    "- implementing a pytorch dataset that scales to larger dataset\n",
    "- adding complexity to the model architecture\n",
    "- etc.\n",
    "\n",
    "But hopefully this gets the basic concepts/workflow across, and make whetted your appetite to try it out for the next modeling challenge. Though do start with a baseline model (e.g. tree-based methods) prior to adding all sorts of complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Blog: An Introduction to Deep Learning for Tabular Data](https://www.fast.ai/2018/04/29/categorical-embeddings/)\n",
    "- [Blog: How 20th Century Fox uses ML to predict a movie audience](https://cloud.google.com/blog/products/ai-machine-learning/how-20th-century-fox-uses-ml-to-predict-a-movie-audience)\n",
    "- [Paper: Covington, Paul and Adams, Jay and Sargin, Emre - Deep Neural Networks for YouTube Recommendations (2016)](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)\n",
    "- [Paper: Haldar, Malay and Abdool, Mustafa and Ramanathan, Prashant and Xu, Tao and Yang, Shulin and Duan, Huizhong and Zhang, Qing and Barrow-Williams, Nick and Turnbull, Bradley C. and Collins, Brendan M. and Legrand, Thomas - Applying Deep Learning To Airbnb Search (2018)](https://arxiv.org/abs/1810.09591)\n",
    "- [PyTorch Documentation - Exporting A Model From PyTorch To ONNX And Running It Using ONNX Runtime](https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225.27px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
