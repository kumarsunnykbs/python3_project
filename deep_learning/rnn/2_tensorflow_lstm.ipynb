{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#LSTM-(Long-Short-Term-Memory)\" data-toc-modified-id=\"LSTM-(Long-Short-Term-Memory)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>LSTM (Long Short Term Memory)</a></span><ul class=\"toc-item\"><li><span><a href=\"#LSTM-Step-by-Step-Walk-Through\" data-toc-modified-id=\"LSTM-Step-by-Step-Walk-Through-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>LSTM Step by Step Walk Through</a></span></li><li><span><a href=\"#Implementation\" data-toc-modified-id=\"Implementation-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Implementation</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2167,
     "status": "ok",
     "timestamp": 1524358132767,
     "user": {
      "displayName": "Ming-Yu Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113235319461992470380"
     },
     "user_tz": 420
    },
    "id": "bcCHLv3Ia3KN",
    "outputId": "610364d9-e543-4c5c-c309-d743b8177da6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    html {\n",
       "        font-size: 18px !important;\n",
       "    }\n",
       "\n",
       "    body {\n",
       "        background-color: #FFF !important;\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    body .notebook-app {\n",
       "        background-color: #FFF !important;\n",
       "    }\n",
       "\n",
       "    #header {\n",
       "        box-shadow: none !important;\n",
       "    }\n",
       "\n",
       "    #notebook {\n",
       "        padding-top: 0px;\n",
       "    }\n",
       "\n",
       "    #notebook-container {\n",
       "        box-shadow: none;\n",
       "        -webkit-box-shadow: none;\n",
       "        padding: 10px;\n",
       "    }\n",
       "\n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border: 1px dashed #CCCCCC;\n",
       "    }\n",
       "\n",
       "    .edit_mode div.cell.selected {\n",
       "        border: 1px dashed #828282;\n",
       "    }\n",
       "\n",
       "    div.output_wrapper {\n",
       "        margin-top: 8px;\n",
       "    }\n",
       "\n",
       "    a {\n",
       "        color: #383838;\n",
       "    }\n",
       "\n",
       "    code,\n",
       "    kbd,\n",
       "    pre,\n",
       "    samp {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem !important;\n",
       "    }\n",
       "\n",
       "    h1 {\n",
       "        font-size: 2rem !important;\n",
       "        font-weight: 500 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: uppercase !important;\n",
       "    }\n",
       "\n",
       "    h2 {\n",
       "        font-size: 1.8rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: none !important;\n",
       "    }\n",
       "\n",
       "    h3 {\n",
       "        font-size: 1.5rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        font-style: italic !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    h4,\n",
       "    h5,\n",
       "    h6 {\n",
       "        font-size: 1rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    .prompt {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem;\n",
       "        text-align: right;\n",
       "        line-height: 1.21429rem;\n",
       "    }\n",
       "\n",
       "    /* INTRO PAGE */\n",
       "\n",
       "    .toolbar_info,\n",
       "    .list-container {\n",
       "        ;\n",
       "    }\n",
       "    /* NOTEBOOK */\n",
       "\n",
       "    div#header-container {\n",
       "        display: none !important;\n",
       "    }\n",
       "\n",
       "    div#notebook {\n",
       "        border-top: none;\n",
       "        font-size: 1rem;\n",
       "    }\n",
       "\n",
       "    div.input_prompt {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .code_cell div.input_prompt:after,\n",
       "    div.output_prompt:after {\n",
       "        content: '\\25b6';\n",
       "    }\n",
       "\n",
       "    div.output_prompt {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    div.input_area {\n",
       "        border-radius: 0px;\n",
       "        border: 1px solid #d8d8d8;\n",
       "    }\n",
       "\n",
       "    div.output_area pre {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    div.output_subarea {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .rendered_html pre,\n",
       "    .rendered_html table,\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        border: 1px #828282 solid;\n",
       "        font-size: 0.75rem;\n",
       "        font-family: 'Menlo', monospace;\n",
       "    }\n",
       "\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        padding: 5px 10px;\n",
       "    }\n",
       "\n",
       "    .rendered_html th {\n",
       "        font-weight: normal;\n",
       "        background: #f8f8f8;\n",
       "    }\n",
       "\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "\n",
       "    div.output_html {\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    table.dataframe tr {\n",
       "        border: 1px #CCCCCC;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border-radius: 0px;\n",
       "    }\n",
       "\n",
       "    div.cell.edit_mode {\n",
       "        border-radius: 0px;\n",
       "        border: thin solid #CF5804;\n",
       "    }\n",
       "\n",
       "    span.ansiblue {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    span.ansigray {\n",
       "        color: #d8d8d8;\n",
       "    }\n",
       "\n",
       "    span.ansigreen {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    span.ansipurple {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    span.ansired {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    span.ansiyellow {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    div.output_stderr {\n",
       "        background-color: #D43132;\n",
       "    }\n",
       "\n",
       "    div.output_stderr pre {\n",
       "        color: #e8e8e8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython.CodeMirror {\n",
       "        background: #F8F8F8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython div.CodeMirror-selected {\n",
       "        background: #e8e8e8 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-gutters {\n",
       "        background: #F8F8F8;\n",
       "        border-right: 0px;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-linenumber {\n",
       "        color: #b8b8b8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-cursor {\n",
       "        border-left: 1px solid #585858 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-atom {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-number {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-property,\n",
       "    .cm-s-ipython span.cm-attribute {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-keyword {\n",
       "        font-weight: normal;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-string {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-operator {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-builtin {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable-2 {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-def {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-error {\n",
       "        background: #FFBDBD;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-tag {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-link {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-matchingbracket {\n",
       "        text-decoration: underline;\n",
       "         !important;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir(os.path.join('..', '..', 'notebook_format'))\n",
    "from formats import load_style\n",
    "load_style(css_style = 'custom2.css', plot_style = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1524358133954,
     "user": {
      "displayName": "Ming-Yu Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113235319461992470380"
     },
     "user_tz": 420
    },
    "id": "LziH-_z1a8oK",
    "outputId": "1a4dc680-10b6-46cc-d520-118f36efe1c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2018-04-27 20:49:11 \n",
      "\n",
      "CPython 3.6.4\n",
      "IPython 6.3.1\n",
      "\n",
      "keras 2.1.5\n",
      "numpy 1.14.2\n",
      "tensorflow 1.7.0\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# 1. magic so that the notebook will reload external python modules\n",
    "# 2. magic to print version\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext watermark\n",
    "%watermark -a 'Ethen' -d -t -v -p keras,numpy,tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (Long Short Term Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've understand the motivation behind Recurrent Neural Network (RNN) and seen its [implementation](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/rnn/1_tensorflow_rnn.ipynb). Let's turn our head towards its more powerful variants.\n",
    "\n",
    "Recall that RNNs are networks with loops in them, allowing them to store information about the previous state and potentially leverage it to better reason about the current state. One popular diagram that we might come across for RNNs is the following:\n",
    "\n",
    "<img src=\"img/rnn_cell.png\" width=\"15%\" height=\"15%\">\n",
    "\n",
    "In the diagram above, a chunk of neural network (our RNN layer) takes some input $x_t$ and outputs a value $h_t$. This loop denotes the network will be repeating the process for every sequence in out input. In other words, when given a sentence of 4 words, the network (the RNN cell) will unrolled itself into 4 copies, one copy for each word.\n",
    "\n",
    "<img src=\"img/rnn_unrolled.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "The main issue with these vanilla RNN is that they tend to suffer from the vanishing gradient problem. Training a RNN is similar to training a traditional Neural Network, we also use the backpropagation algorithm, but with a little twist. Because the parameters are shared by all time steps in the network, the gradient at each output depends not only on the calculations of the current time step, but also the previous time steps. For example, in order to calculate the gradient at t=4 we would need to backpropagate 3 steps and sum up the gradients. This is called Backpropagation Through Time (BPTT). Thus we can imagine when computing the gradient, if we multiply a small number with another small number with another and with another, the value dramatically decays to 0, and the weights will no longer be updated when the gradients are 0. To mitigate this issue, other variants of RNNs were developed, and this notebook will look at one of them called **LSTM (Long Short Term Memory)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Step by Step Walk Through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a large portion of the content for this section is based on [Blog: Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "Given $x_t$, the input at time step $t$ and $h_t$, the hidden state at time step $t$ the computation happening in a vanilla RNN cell are as follow:\n",
    "\n",
    "<img src=\"img/rnn_forward.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "\\begin{align}\n",
    "h_t = f(W h_{t - 1} + U x_t)\n",
    "\\end{align}\n",
    "\n",
    "Here, $f$ is usually a nonlinearity function such as tanh. LSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single set of weights $U$ and $W$ connecting the input and hidden state respectively, there are four sets of weights, interacting in a very special way.\n",
    "\n",
    "LSTM are designed to avoid long-term dependency problems, and the core idea is the cell state, the horizontal line running through the top of the diagram.\n",
    "\n",
    "<img src=\"img/cell_state.png\" width=\"50%\" height=\"50%\">\n",
    "\n",
    "\n",
    "Cell state is kind of like a conveyor belt. It runs straight down the entire chain, with only some linear interactions, making it easier for information to flow along it unchanged. LSTMs have the ability to remove or add information to the cell state, carefully regulated by structures called gates. Namely, the **forget gate, input gate and output gate**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step for a LSTM cell is to decide what information we're going to throw away from the cell state. This is determined by the a sigmoid layer \"forget gate\", the forget gate looks at $h_{t−1}$ and $x_t$, and outputs a number between 0 and 1 for each number in the cell state $C_{t−1}$. A 1 represents completely keep this while a 0 represents completely get rid of this.\n",
    "\n",
    "<img src=\"img/forget_gate.png\" width=\"40%\" height=\"40%\">\n",
    "\n",
    "\\begin{align}\n",
    "f_t = \\sigma(W_f \\cdot [ h_{t - 1}, x_t ] + b_f)\n",
    "\\end{align}\n",
    "\n",
    "Note that $W_f \\cdot [ h_{t - 1}, x_t ]$ is a simplified notation for $W h_{t - 1} + U x_t$, $W_f$ denotes that these are the set of weights for the forget gate.\n",
    "\n",
    "For example, if we are building a language model that's trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, to determine the correct pronouns to use. When we see a new subject, we want to forget the gender of the old subject.\n",
    "\n",
    "The second step is to determine what new information to store in the cell state. This step consists of two parts, first a sigmoid layer known as the \"input gate\" decides which value we'll update. Second, a tanh layer creates a vector of new candidate value $\\tilde{C_t}$, that could be added to the state.\n",
    "\n",
    "<img src=\"img/input_gate.png\" width=\"40%\" height=\"40%\">\n",
    "\n",
    "\\begin{align}\n",
    "i_t &= \\sigma(W_i \\cdot [ h_{t - 1}, x_t ] + b_i) \\\\\n",
    "\\tilde{C_t} &= tanh(W_c \\cdot [ h_{t - 1}, x_t ] + b_c)\n",
    "\\end{align}\n",
    "\n",
    "In the example of our language model, we want to add the gender of the new subject to the cell state to replace the old one we're forgetting.\n",
    "\n",
    "It's now time to update the old cell state, $C_{t−1}$, into the new cell state $C_t$. The previous steps already decided what to do, we just need to actually do it. We multiply the old state by $f_t$, forgetting the things we've decided to forget earlier. Then we add $i_t * \\tilde{C_t}$, which is the new cell state scaled by how much we've decided to update each value.\n",
    "\n",
    "<img src=\"img/update_cell.png\" width=\"40%\" height=\"40%\">\n",
    "\n",
    "\\begin{align}\n",
    "C_t &= f_t * C_{t-1} + i_t * \\tilde{C_t}\n",
    "\\end{align}\n",
    "\n",
    "Looking at this formula more carefully, we can see that the information carried by the previous cell state, $C_{t-1}$ will not be lost if its weight, i.e. the forget gate $f_t$ is on (close to 1), making LSTM better at learning long-term dependencies compared to vanilla RNN.\n",
    "\n",
    "In the case of the language model, this is where we'd actually drop the information about the old subject's gender and add the new information, as we decided in the previous steps.\n",
    "\n",
    "Finally, we need to decide what we're going to output. This output will be a filtered version of our cell state. First, we run it through a sigmoid layer which decides what parts of the cell state we're going to output. This is essentially our output gate. Then, we put the cell state through tanh (to push the values to be between −1 and 1) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.\n",
    "\n",
    "\n",
    "<img src=\"img/output_gate.png\" width=\"40%\" height=\"40%\">\n",
    "\n",
    "\\begin{align}\n",
    "o_t &= \\sigma(W_o \\cdot [ h_{t - 1}, x_t ] + b_o) \\\\\n",
    "h_t &= o_t * tanh(C_t)\n",
    "\\end{align}\n",
    "\n",
    "For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that's what is coming next. Or it might output whether the subject is singular or plural, so that we know what form a verb the next word should take form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the scripts is similar to that of the implementation for vanilla [RNN](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/rnn/1_tensorflow_rnn.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 796,
     "status": "ok",
     "timestamp": 1524358135109,
     "user": {
      "displayName": "Ming-Yu Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113235319461992470380"
     },
     "user_tz": 420
    },
    "id": "71b43RtcxqFi",
    "outputId": "a55df026-eccd-4f2c-d1f8-d981faff86f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist data shape:  (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# images takes values between 0 - 255, we can normalize it\n",
    "# by dividing every number by 255\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('mnist data shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1524358135549,
     "user": {
      "displayName": "Ming-Yu Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113235319461992470380"
     },
     "user_tz": 420
    },
    "id": "hhf0iI3JxrUC",
    "outputId": "1c7a4f55-14cf-4c1f-f11e-3ea1ad2178e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label shape:  (128, 10)\n",
      "data shape:  (128, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from dataloader import DataLoader\n",
    "\n",
    "\n",
    "# Define some parameters\n",
    "element_size = 28\n",
    "time_steps = 28\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# example of generating a batch of data using the\n",
    "# DataLoader class\n",
    "data_loader = DataLoader(X_train, Y_train, num_classes)\n",
    "X_batch, y_batch = data_loader.next_batch(batch_size)\n",
    "print('label shape: ', y_batch.shape)\n",
    "print('data shape: ', X_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formulas for LSTM is listed again for quick reference, note that for the implementation, we've excluded the bias term to keep things simpler.\n",
    "\n",
    "\\begin{align}\n",
    "f_t &= \\sigma(W_f \\cdot [ h_{t - 1}, x_t ] + b_f) \\nonumber \\\\\n",
    "i_t &= \\sigma(W_i \\cdot [ h_{t - 1}, x_t ] + b_i) \\nonumber \\\\\n",
    "\\tilde{C_t} &= tanh(W_c \\cdot [ h_{t - 1}, x_t ] + b_c) \\nonumber \\\\\n",
    "C_t &= f_t * C_{t-1} + i_t * \\tilde{C_t} \\nonumber \\\\\n",
    "o_t &= \\sigma(W_o \\cdot [ h_{t - 1}, x_t ] + b_o) \\nonumber \\\\\n",
    "h_t &= o_t * tanh(C_t)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c24nUczfhbb-"
   },
   "outputs": [],
   "source": [
    "# the first dimension holds the batch size\n",
    "inputs = tf.placeholder(tf.float32, shape = [None, time_steps, element_size], name = 'inputs')\n",
    "labels = tf.placeholder(tf.float32, shape = [None, num_classes], name = 'labels')\n",
    "\n",
    "# U : input's weight\n",
    "# W : hidden state's weight\n",
    "# the first dimension is 4 since we have 4 sets of these weights,\n",
    "# 1 for forget gate, 1 for input gate, 1 for candidate cell state\n",
    "# and 1 for output gate. We'll create them in 1 place and slice\n",
    "# it to access each one\n",
    "U = tf.Variable(tf.zeros([4, element_size, hidden_layer_size]))\n",
    "W = tf.Variable(tf.zeros([4, hidden_layer_size, hidden_layer_size]))\n",
    "\n",
    "\n",
    "def lstm_step(previous_hidden_state, x):\n",
    "    # lstm contains 2 sets of hidden state weights, 1 for the cell state\n",
    "    # and the other for the output state (originally the hidden state for\n",
    "    # vanilla RNN)\n",
    "    output_state, cell_state = tf.unstack(previous_hidden_state)\n",
    "\n",
    "    input_gate = tf.sigmoid(tf.matmul(x, U[0]) + tf.matmul(output_state, W[0]))\n",
    "    forget_gate = tf.sigmoid(tf.matmul(x, U[1]) + tf.matmul(output_state, W[1]))\n",
    "    output_gate = tf.sigmoid(tf.matmul(x, U[2]) + tf.matmul(output_state, W[2]))\n",
    "    candidate_cell_state = tf.tanh(tf.matmul(x, U[3]) + tf.matmul(output_state, W[3]))\n",
    "\n",
    "    new_cell_state = forget_gate * cell_state + input_gate * candidate_cell_state\n",
    "    new_output_state = output_gate * tf.tanh(new_cell_state)\n",
    "    current_hidden_state = tf.stack([new_output_state, new_cell_state])\n",
    "    return current_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1258,
     "status": "ok",
     "timestamp": 1524358137230,
     "user": {
      "displayName": "Ming-Yu Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113235319461992470380"
     },
     "user_tz": 420
    },
    "id": "W-alJzyUk2mb",
    "outputId": "91c89c4b-b978-4dbd-a3cb-55dc9e90d055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 2, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# the original input batch's shape is of [batch_size, time_steps and element_size]\n",
    "# we permutate the order to [time_steps, batch_size, element_size]. The time_steps\n",
    "# is put up front in order to leverage tf.scan's functionality\n",
    "input_reshaped = tf.transpose(inputs, perm = [1, 0, 2])\n",
    "\n",
    "# we initialize a hidden state to begin with and apply the rnn steps using tf.scan,\n",
    "# which repeatedly applies a callable to our inputs\n",
    "initial_hidden = tf.zeros([2, batch_size, hidden_layer_size])\n",
    "all_hidden_states = tf.scan(\n",
    "    lstm_step, input_reshaped, initializer = initial_hidden, name = 'hidden_states')\n",
    "\n",
    "# if we do a fake run, we can see that the output at this point is the hidden state\n",
    "# for every time step [time_steps, 2, batch_size, hidden_layer_size]\n",
    "# 2 is for the 2 sets of hidden state LSTM has\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    data_loader = DataLoader(X_train, Y_train, num_classes)\n",
    "    X_batch, y_batch = data_loader.next_batch(batch_size)\n",
    "    temp = sess.run(all_hidden_states, feed_dict = {inputs: X_batch, labels: y_batch})\n",
    "    print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ccZrawStlhkA"
   },
   "outputs": [],
   "source": [
    "# output linear layer's weight and bias, V from the diagram\n",
    "Wl = tf.Variable(tf.truncated_normal(\n",
    "    [hidden_layer_size, num_classes],\n",
    "    mean = 0, stddev = .01))\n",
    "bl = tf.Variable(tf.truncated_normal(\n",
    "    [num_classes], mean = 0,stddev = .01))\n",
    "\n",
    "# apply linear layer to state vector;\n",
    "# instead of calculating the output vector for every hidden state,\n",
    "# in basic classification, we can assume the last hidden state\n",
    "# has accumulated the information representing the entire sequence\n",
    "states = tf.reshape(all_hidden_states[-1, 0], [-1, hidden_layer_size])\n",
    "output = tf.matmul(states, Wl) + bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bzjr74Rzffat"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "# specify the cross entropy loss, the optimizer to train the loss,\n",
    "# the accuracy measurement\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits = output, labels = labels))\n",
    "train_step = tf.train.RMSPropOptimizer(learning_rate).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(labels, axis = 1), tf.argmax(output, axis = 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76331,
     "status": "ok",
     "timestamp": 1524358227134,
     "user": {
      "displayName": "Ming-Yu Liu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113235319461992470380"
     },
     "user_tz": 420
    },
    "id": "NSeCPQlusgQ_",
    "outputId": "b0806101-723f-4035-b94e-d0c031a0fb1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Minibatch Loss = 2.30216, Training Accuracy = 14.0625\n",
      "Iter 1000, Minibatch Loss = 0.82200, Training Accuracy = 70.3125\n",
      "Iter 2000, Minibatch Loss = 0.24636, Training Accuracy = 93.7500\n",
      "Iter 3000, Minibatch Loss = 0.08379, Training Accuracy = 98.4375\n",
      "Iter 4000, Minibatch Loss = 0.02557, Training Accuracy = 99.2188\n",
      "Optimization finished!\n",
      "Test Accuracy:  98.4375\n",
      "elapse time:  197.55520510673523\n"
     ]
    }
   ],
   "source": [
    "X_test_batch = X_test[:batch_size]\n",
    "y_test_batch = to_categorical(Y_test[:batch_size], num_classes)\n",
    "\n",
    "data_loader = DataLoader(X_train, Y_train, num_classes)\n",
    "\n",
    "epochs = 5000\n",
    "with tf.Session() as sess:    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    start = time()\n",
    "    for i in range(epochs):\n",
    "        X_batch, y_batch = data_loader.next_batch(batch_size)\n",
    "        sess.run(train_step, feed_dict = {inputs: X_batch, labels: y_batch})\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            acc, loss = sess.run([accuracy, cross_entropy],\n",
    "                                 feed_dict = {inputs: X_batch, labels: y_batch})\n",
    "            print(\"Iter \" + str(i) + \", Minibatch Loss =\",\n",
    "                  \"{:.5f}\".format(loss) + \", Training Accuracy =\",\n",
    "                  \"{:.4f}\".format(acc))\n",
    "\n",
    "    print('Optimization finished!')\n",
    "    acc_test = sess.run(accuracy, feed_dict = {inputs: X_test_batch, labels: y_test_batch})\n",
    "    print('Test Accuracy: ', acc_test)\n",
    "    print('elapse time: ', time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the more complex structure, it makes sense that it takes longer for LSTMs to train compared to vanilla RNN. But, thankfully, it does give better performance on the test set. \n",
    "\n",
    "Most of exciting result today achieved by RNN-like networks is in fact achieved by LSTMs, because of its capability to deal with long term dependency. The long term dependency problem is that, when we have larger network through time, the gradient decays quickly during back propagation. So training a RNN having long unfolding in time becomes impossible. But LSTM avoids this decay of gradient problem by allowing us to make a super highway (cell states) through time, these highways allow the gradient to freely flow backward in time making them less susceptible to vanishing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "- [Blog: Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- [Blog: Unfolding RNNs II - Vanilla, GRU, LSTM RNNs from scratch in Tensorflow](http://suriyadeepan.github.io/2017-02-13-unfolding-rnn-2/)\n",
    "- [Quora: How does LSTM help prevent the vanishing (and exploding) gradient problem in a recurrent neural network?](https://www.quora.com/How-does-LSTM-help-prevent-the-vanishing-and-exploding-gradient-problem-in-a-recurrent-neural-network)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "tensorflow_rnn.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "251px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
