{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Gradient-Boosted-Tree-Inferencing\" data-toc-modified-id=\"Gradient-Boosted-Tree-Inferencing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Gradient Boosted Tree Inferencing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Translating-to-Production-Language\" data-toc-modified-id=\"Translating-to-Production-Language-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Translating to Production Language</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preparation\" data-toc-modified-id=\"Preparation-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Preparation</a></span></li><li><span><a href=\"#Regression\" data-toc-modified-id=\"Regression-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Regression</a></span></li><li><span><a href=\"#Binary-Classification\" data-toc-modified-id=\"Binary-Classification-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Binary Classification</a></span></li><li><span><a href=\"#Multiclass-Classification\" data-toc-modified-id=\"Multiclass-Classification-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Multiclass Classification</a></span></li><li><span><a href=\"#C++-Implementation\" data-toc-modified-id=\"C++-Implementation-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>C++ Implementation</a></span></li></ul></li><li><span><a href=\"#ONNX\" data-toc-modified-id=\"ONNX-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>ONNX</a></span></li></ul></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.260822Z",
     "start_time": "2021-02-07T18:25:13.175096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Ethen\n",
      "\n",
      "Last updated: 2022-06-02\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.11\n",
      "IPython version      : 7.27.0\n",
      "\n",
      "numpy  : 1.21.6\n",
      "pandas : 1.3.5\n",
      "sklearn: 1.0.2\n",
      "m2cgen : 0.10.0\n",
      "xgboost: 1.6.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. magic to print version\n",
    "# 2. magic so that the notebook will reload external python modules\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import m2cgen as m2c\n",
    "import sklearn.datasets as datasets\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import onnxruntime as rt\n",
    "from skl2onnx import convert_sklearn, update_registered_converter\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes\n",
    "from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost\n",
    "\n",
    "# prevent scientific notations\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%watermark -a 'Ethen' -u -d -v -p numpy,pandas,sklearn,m2cgen,xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we train our machine learning model, depending on the use case, we may wish to operationize it by putting it behind a service for (near) real time inferencing. We can definitely generate predictions in batch offline, store them in some downstream tables or look up services, and pull out pre-computed predictions when needed. Although this batch prediction approach might sound easier to implement, and we might not have to worry about latency issues when it comes to real time services, this paradigm does come with its limitations. e.g.\n",
    "\n",
    "- Cold start problem, if a new entity, whether it's users coming to the website or items being listed on a marketplace, there will be no precomputed recommendations available.\n",
    "- Not having access to real time features. Dynamic features are features based on what’s happening right now – what a user is watching, what people just liked, knowing these will allow us to generate more accurate or relevant predictions based on latest information.\n",
    "- Potentially wasted computation/storage. If we generate predictions for every possible user each day, and only 5% of them login to use our website, then the compute used to generate 95% of our predictions will be wasted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating to Production Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very common in industry setting to prototype a machine learning model in Python and translate it into other languages such as C++, Java, etc, when it comes to deploying. This usually happens where the core application is written in other languages such as C++, Java, etc. and it is an extremely time sensitive application where we can't afford the cost of calling an external API to fetch the model prediction.\n",
    "\n",
    "In this section, we'll be looking at how we can achieve this with Gradient Boosted Trees, specifically XGBoost. Different library might have different ways to doing this, but the concept should be similar.\n",
    "\n",
    "**Tree Structure**\n",
    "\n",
    "A typical model dump from XGBoost looks like the following:\n",
    "\n",
    "```\n",
    "booster[0]:\n",
    "0:[bmi<0.00942232087] yes=1,no=2,missing=1\n",
    "\t1:[bmi<-0.0218342301] yes=3,no=4,missing=3\n",
    "\t\t3:[bmi<-0.0584798381] yes=7,no=8,missing=7\n",
    "\t\t\t7:leaf=25.84091\n",
    "\t\t\t8:leaf=33.0292702\n",
    "\t\t4:[bp<0.0270366594] yes=9,no=10,missing=9\n",
    "\t\t\t9:leaf=38.7487526\n",
    "\t\t\t10:leaf=51.0882378\n",
    "\t2:[bp<0.0235937908] yes=5,no=6,missing=5\n",
    "\t\t5:leaf=53.0696678\n",
    "\t\t6:leaf=69.4000015\n",
    "booster[1]:\n",
    "0:[bmi<0.00511107268] yes=1,no=2,missing=1\n",
    "\t1:[bp<0.0390867069] yes=3,no=4,missing=3\n",
    "\t\t3:[bmi<-0.0207564179] yes=7,no=8,missing=7\n",
    "\t\t\t7:leaf=21.0474758\n",
    "\t\t\t8:leaf=27.7326946\n",
    "\t\t4:[bmi<0.000799824367] yes=9,no=10,missing=9\n",
    "\t\t\t9:leaf=36.1850548\n",
    "\t\t\t10:leaf=14.9188232\n",
    "\t2:[bmi<0.0730132312] yes=5,no=6,missing=5\n",
    "\t\t5:[bp<6.75072661e-05] yes=11,no=12,missing=11\n",
    "\t\t\t11:leaf=31.3889732\n",
    "\t\t\t12:leaf=43.4056664\n",
    "\t\t6:[bp<-0.0498541184] yes=13,no=14,missing=13\n",
    "\t\t\t13:leaf=13.0395498\n",
    "\t\t\t14:leaf=59.377037\n",
    "```\n",
    "\n",
    "There are 3 distinct information:\n",
    "\n",
    "- `booster` Gradient Boosting Tree is an ensemble tree method, each new booster indicates the start of a new tree. The number of trees we have will be equivalent to the number of trees we specified for the model (e.g. for the sklearn XGBoost API, `n_estimators` controls this) multiplied by the number of distinct classes. For regression model or binary classification model, the number of booster in the model dump will be exactly equal to the number of trees we've specified. Whereas for multi class classification, say we have 3 classes, then tree 0 will contribute to the raw prediction of class 0, tree 1 to class 1, tree 2 to class 2, tree 3 to class 0 and so on.\n",
    "- `node` Following the booster is each tree's if-else structure. e.g. for node 0, if the feature `bmi` is less than a threshold, then it will branch to node 1 else it will branch to node 2.\n",
    "- `leaf` Once we reach the leaf, we can accumulate the response prediction. e.g. node 7 is a leaf, and the prediction for this node is 25.84091.\n",
    "\n",
    "\n",
    "**Raw Prediction**\n",
    "\n",
    "We mentioned that to get the prediction for a given input, we sum up the response prediction associated from each tree's leaf node. The holds true for regression models, but for other models, we will need to perform a transformation on top the raw prediction to get to the probabilities. e.g. for when building a binary classification, a logistic transformation will be needed on top of the raw prediction, whereas for the multi-class classification, a softmax transformation is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the examples below, be it regression, binary classification or multi class classification all follow the same structure.\n",
    "\n",
    "- We load some pre-processed data.\n",
    "- Train a quick XGBoost model.\n",
    "- Dump the raw model to disk.\n",
    "- Generate a sample prediction so we can later verify whether the prediction matches with the model converted to cpp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.369007Z",
     "start_time": "2021-02-07T18:25:19.263740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age    sex    bmi     bp\n",
       "0  0.038  0.051  0.062  0.022\n",
       "1 -0.002 -0.045 -0.051 -0.026\n",
       "2  0.085  0.051  0.044 -0.006\n",
       "3 -0.089 -0.045 -0.012 -0.037\n",
       "4  0.005 -0.045 -0.036  0.022"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "X = X[[\"age\", \"sex\", \"bmi\", \"bp\"]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.421190Z",
     "start_time": "2021-02-07T18:25:19.371371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.0, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=2, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model_params = {\n",
    "    'n_estimators': 2,\n",
    "    'max_depth': 3,\n",
    "    'base_score': 0.0\n",
    "}\n",
    "regression_model = XGBRegressor(**regression_model_params).fit(X, y)\n",
    "regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.479705Z",
     "start_time": "2021-02-07T18:25:19.423567Z"
    }
   },
   "outputs": [],
   "source": [
    "regression_model.get_booster().dump_model(\"regression.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.521771Z",
     "start_time": "2021-02-07T18:25:19.484379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([96.475334], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.predict(X.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.573940Z",
     "start_time": "2021-02-07T18:25:19.532177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.24456934, -1.36232827,  1.55433334, -2.0869092 , -1.27760482],\n",
       "       [-0.46503462, -0.57657929, -0.2033143 ,  0.43042571,  1.98019634],\n",
       "       [ 1.0967453 ,  1.31568265,  0.40073014, -0.88575625,  0.72711376],\n",
       "       ...,\n",
       "       [-3.17646599, -2.97878542,  0.32401442,  0.12710402, -0.63318634],\n",
       "       [-0.41224819,  0.17380558,  1.04229889, -1.62625451, -1.24718999],\n",
       "       [-1.02487223, -0.70828082,  0.55578021, -0.70007904, -0.43269446]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = datasets.make_classification(n_samples=10000, n_features=5, random_state=42, n_classes=2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.637949Z",
     "start_time": "2021-02-07T18:25:19.577514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='lossguide',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=3, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model_params = {\n",
    "    'n_estimators': 3,\n",
    "    'max_depth': 3,\n",
    "    'tree_method': 'hist',\n",
    "    'grow_policy': 'lossguide'\n",
    "}\n",
    "binary_model = XGBClassifier(**binary_model_params).fit(X, y)\n",
    "binary_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.675808Z",
     "start_time": "2021-02-07T18:25:19.640919Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_model.get_booster().dump_model(\"binary_class.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.729845Z",
     "start_time": "2021-02-07T18:25:19.688789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2894203, 0.7105797]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([[0.0, 0.2, 0.4, 0.6, 0.8]])\n",
    "binary_model.predict_proba(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.778573Z",
     "start_time": "2021-02-07T18:25:19.732064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.100</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.900</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.700</td>\n",
       "      <td>3.200</td>\n",
       "      <td>1.300</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.600</td>\n",
       "      <td>3.100</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000</td>\n",
       "      <td>3.600</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0              5.100             3.500              1.400             0.200\n",
       "1              4.900             3.000              1.400             0.200\n",
       "2              4.700             3.200              1.300             0.200\n",
       "3              4.600             3.100              1.500             0.200\n",
       "4              5.000             3.600              1.400             0.200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True, as_frame=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.825299Z",
     "start_time": "2021-02-07T18:25:19.782537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=2, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_class_model_params = {\n",
    "    'n_estimators': 2,\n",
    "    'max_depth': 3\n",
    "}\n",
    "multi_class_model = XGBClassifier(**multi_class_model_params).fit(X, y)\n",
    "multi_class_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.867799Z",
     "start_time": "2021-02-07T18:25:19.829309Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_class_model.get_booster().dump_model(\"multi_class.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.906184Z",
     "start_time": "2021-02-07T18:25:19.870241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6092037 , 0.19627655, 0.19451974]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
    "multi_class_model.predict_proba(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++ Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the content is about implementing the boosted tree inferencing logic in C++, all the code resides in the [`gbt_inference`](https://github.com/ethen8181/machine-learning/tree/master/model_deployment/gbt_inference/gbt_inference) folder for those interested. In practice, we don't always have to rely on naive code that we've implemented to solidify our understanding. e.g. the [m2cgen (Model 2 Code Generator)](https://github.com/BayesWitnesses/m2cgen) project is one of the many projects out there that focuses on converting a trained model into native code. If we export our regression model, we can see that the inferencing logic is indeed a bunch of if else statements followed by a summation at the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T18:25:19.949779Z",
     "start_time": "2021-02-07T18:25:19.908688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double score(double * input) {\n",
      "    double var0;\n",
      "    if (input[2] >= 0.009422321) {\n",
      "        if (input[3] >= 0.02359379) {\n",
      "            var0 = 69.4;\n",
      "        } else {\n",
      "            var0 = 53.069668;\n",
      "        }\n",
      "    } else {\n",
      "        if (input[2] >= -0.02183423) {\n",
      "            if (input[3] >= 0.02703666) {\n",
      "                var0 = 51.088238;\n",
      "            } else {\n",
      "                var0 = 38.748753;\n",
      "            }\n",
      "        } else {\n",
      "            if (input[2] >= -0.058479838) {\n",
      "                var0 = 33.02927;\n",
      "            } else {\n",
      "                var0 = 25.84091;\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "    double var1;\n",
      "    if (input[2] >= 0.0051110727) {\n",
      "        if (input[2] >= 0.07301323) {\n",
      "            if (input[3] >= -0.04985412) {\n",
      "                var1 = 59.377037;\n",
      "            } else {\n",
      "                var1 = 13.03955;\n",
      "            }\n",
      "        } else {\n",
      "            if (input[3] >= 0.000067507266) {\n",
      "                var1 = 43.405666;\n",
      "            } else {\n",
      "                var1 = 31.388973;\n",
      "            }\n",
      "        }\n",
      "    } else {\n",
      "        if (input[3] >= 0.039086707) {\n",
      "            if (input[2] >= 0.00079982437) {\n",
      "                var1 = 14.918823;\n",
      "            } else {\n",
      "                var1 = 36.185055;\n",
      "            }\n",
      "        } else {\n",
      "            if (input[2] >= -0.020756418) {\n",
      "                var1 = 27.732695;\n",
      "            } else {\n",
      "                var1 = 21.047476;\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "    return var0 + var1;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code = m2c.export_to_c(regression_model)\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to achieving this is through ONNX, directly quoting from its documentation.\n",
    "\n",
    "> ONNX Runtime provides an easy way to run machine learned models with high performance on CPU or GPU without dependencies on the training framework. Machine learning frameworks are usually optimized for batch training rather than for prediction, which is a more common scenario in applications, sites, and services\n",
    "\n",
    "We'll walk through the process of converting our boosted tree model into ONNX format, and benchmark the inference runtime. Here, we are doing it for classification model, but the process should be similar for regression based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rows: 10000, num cols: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.24456934, -1.36232827,  1.55433334, -2.0869092 , -1.27760482],\n",
       "       [-0.46503462, -0.57657929, -0.2033143 ,  0.43042571,  1.98019634],\n",
       "       [ 1.0967453 ,  1.31568265,  0.40073014, -0.88575625,  0.72711376],\n",
       "       ...,\n",
       "       [-3.17646599, -2.97878542,  0.32401442,  0.12710402, -0.63318634],\n",
       "       [-0.41224819,  0.17380558,  1.04229889, -1.62625451, -1.24718999],\n",
       "       [-1.02487223, -0.70828082,  0.55578021, -0.70007904, -0.43269446]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 5\n",
    "X, y = datasets.make_classification(n_samples=10000, n_features=n_features, random_state=42, n_classes=2)\n",
    "feature_names = [f'f{i}'for i in range(n_features)]\n",
    "print(f'num rows: {X.shape[0]}, num cols: {X.shape[1]}')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.57050\n",
      "[1]\tvalidation_0-logloss:0.48945\n",
      "[2]\tvalidation_0-logloss:0.42726\n",
      "[3]\tvalidation_0-logloss:0.38211\n",
      "[4]\tvalidation_0-logloss:0.34932\n",
      "[5]\tvalidation_0-logloss:0.32240\n",
      "[6]\tvalidation_0-logloss:0.29620\n",
      "[7]\tvalidation_0-logloss:0.27869\n",
      "[8]\tvalidation_0-logloss:0.26133\n",
      "[9]\tvalidation_0-logloss:0.25024\n",
      "[10]\tvalidation_0-logloss:0.24013\n",
      "[11]\tvalidation_0-logloss:0.23271\n",
      "[12]\tvalidation_0-logloss:0.22679\n",
      "[13]\tvalidation_0-logloss:0.22081\n",
      "[14]\tvalidation_0-logloss:0.21672\n",
      "[15]\tvalidation_0-logloss:0.21081\n",
      "[16]\tvalidation_0-logloss:0.20629\n",
      "[17]\tvalidation_0-logloss:0.20226\n",
      "[18]\tvalidation_0-logloss:0.19999\n",
      "[19]\tvalidation_0-logloss:0.19766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.2, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=20, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = XGBClassifier(\n",
    "    n_estimators=20,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.2,\n",
    "    tree_method='hist',\n",
    "    verbosity=1\n",
    ")\n",
    "tree.fit(X, y, eval_set=[(X, y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9862067, 0.0137933]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict_proba(X[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_checkpoint = 'model.json'\n",
    "tree.save_model(xgboost_checkpoint)\n",
    "tree_loaded = XGBClassifier()\n",
    "tree_loaded.load_model(xgboost_checkpoint)\n",
    "\n",
    "assert np.allclose(tree.predict_proba(X[:1]), tree_loaded.predict_proba(X[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_payloads = [\n",
    "    {\n",
    "        'f0': -2.24456934,\n",
    "        'f1': -1.36232827,\n",
    "        'f2': 1.55433334,\n",
    "        'f3': -2.0869092,\n",
    "        'f4': -1.27760482\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0137933], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for input_payload in input_payloads:\n",
    "    row = [input_payload[feature] for feature in feature_names]\n",
    "    rows.append(row)\n",
    "\n",
    "np_rows = np.array(rows, dtype=np.float32)\n",
    "tree.predict_proba(np_rows)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896 µs ± 29.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rows = []\n",
    "for input_payload in input_payloads:\n",
    "    row = [input_payload[feature] for feature in feature_names]\n",
    "    rows.append(row)\n",
    "\n",
    "np_rows = np.array(rows, dtype=np.float32)\n",
    "tree.predict_proba(np_rows)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xgboost_to_onnx(model, num_features: int, checkpoint: str):\n",
    "    \n",
    "    # boiler plate code for registering the xgboost converter\n",
    "    update_registered_converter(\n",
    "        XGBClassifier, 'XGBoostXGBClassifier',\n",
    "        calculate_linear_classifier_output_shapes, convert_xgboost,\n",
    "        options={'nocl': [True, False], 'zipmap': [True, False, 'columns']}\n",
    "    )\n",
    "    # perform the actual conversion specifying the types of our inputs,\n",
    "    # at the time of writing this, it doesn't support categorical types\n",
    "    # that are common in boosted tree libraries such as xgboost or lightgbm\n",
    "    model_onnx = convert_sklearn(\n",
    "        model, 'xgboost',\n",
    "        [('input', FloatTensorType([None, num_features]))],\n",
    "        target_opset={'': 15, 'ai.onnx.ml': 2}\n",
    "    )\n",
    "\n",
    "    with open(checkpoint, \"wb\") as f:\n",
    "        f.write(model_onnx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_checkpoint = 'xgboost.onnx'\n",
    "convert_xgboost_to_onnx(tree, len(feature_names), onnx_model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon porting our model to onnx format, we can use it for inferencing. This section uses the Python API for benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(onnx_model_checkpoint)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_names = [output.name for output in sess.get_outputs()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 0.9862067103385925, 1: 0.01379328966140747}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_rows = np.array(rows, dtype=np.float32)\n",
    "onnx_predict_label, onnx_predict_score = sess.run(output_names, {input_name: np_rows})\n",
    "onnx_predict_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.6 µs ± 365 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rows = []\n",
    "for input_payload in input_payloads:\n",
    "    row = [input_payload[feature] for feature in feature_names]\n",
    "    rows.append(row)\n",
    "\n",
    "np_rows = np.array(rows, dtype=np.float32)\n",
    "onnx_predict_label, onnx_predict_score = sess.run(output_names, {input_name: np_rows})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, at the time of writing this document, the onnx converter [doesn't support categorical variables splits](https://github.com/onnx/onnxmltools/issues/309) from common boosted tree libraries such as [xgboost](https://xgboost.readthedocs.io/en/latest/tutorials/categorical.html) or [lightgbm](https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html#categorical-feature-support), we will have to leverage other ways of dealing with categorical variables if we wish to leverage onnx for inferencing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Blog: Roll your own XGBoost model](https://medium.com/swlh/roll-your-own-xgboost-model-7490106b9523)\n",
    "- [Doc: Sklearn-onnx Convert a pipeline with a XGBoost model](https://onnx.ai/sklearn-onnx/auto_tutorial/plot_gexternal_xgboost.html)\n",
    "- [Blog: Real-time machine learning: challenges and solutions](https://huyenchip.com/2022/01/02/real-time-machine-learning-challenges-and-solutions.html)\n",
    "- [Blog: Seven Reasons Why Realtime ML Is Here To Stay](https://blog.fennel.ai/p/seven-reasons-why-realtime-ml-is)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
